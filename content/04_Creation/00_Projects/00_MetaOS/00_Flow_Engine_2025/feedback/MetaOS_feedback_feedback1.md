
## 스타트
초기: 한국어로 시작하고 반응등을 사례로 피드백
글로벌: 국제화,[[i8n]]을 추가

## 메타-OS용도(=실험장소, 작업방), 기술적 피드백
클라이언트 사이드와 서버사이드 AI모델 호출, 메모리 상태 관리
> 피드백 루프 등 복잡한 기능이 들어가면 확장 가능한 마이크로 서비스 아키텍처나 별도 벡엔드 API서버 구축도 구려가능

### 로컬 모델과 Mistral-small API를 동시에 활용하는 방법에 대해
안정적인 서비스 제공 및 요청량이 많아질 경우를 대비해
캐싱,로드 밸런싱, 모니터링 등을 미리 고려해두면 좋겠다.

실험결과는 Colab,Kaggle을 사용하고 실제 운영환경에서는 Docker,Kubernetes 또는 서버리스 방식으로 배포해 확장성을 확보하는 것도 좋다.

## MVP + 피드백 루프
실험가능 하며 -> "메모리 업데이트","감정/의도"기반 인터렉션 등을 실제 사용자 시나리오에 적용
특정 사용자 집중 -> 추가 기능을 점진적으로 넣는다

### 피드백 루프
UserLog, 반응, 피드백 데이터를 체계적으로 수집 -> 분석 -> 모델 및 시스템 개선 -> 자기화 루프 효과를 극대화 가능하다.

"스탭 바이스텝" 가이드는 별도 브랜드 또는 플랫폼으로 분리후 론칭한다.